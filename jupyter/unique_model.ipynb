{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# train one unique model\n",
    "\n",
    "1. without special token (emoji, url, ...)\n",
    "2. with special token\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.41 seconds)\n",
      "Writing emoji data to /root/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import my_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Without special token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               tweet label enterprise  \\\n0              20 min line @apple store @short pump.     1          0   \n1  Nueva tecnología convierte cualquier superfici...     3          1   \n2  Some people should not post replies in #Google...     1          2   \n3  I know a few others having same issue RT @Joel...     2          0   \n4  #Microsoft - We put the \"\"backwards\"\" into bac...     2          1   \n\n   is_irrelevant                                         token_list  \\\n0              0              20 min line @apple store @short pump.   \n1              1  Nueva tecnología convierte cualquier superfici...   \n2              0  Some people should not post replies in #Google...   \n3              0  I know a few others having same issue RT @Joel...   \n4              0  #Microsoft - We put the \"\"backwards\"\" into bac...   \n\n                                       number_vector  \\\n0  [592, 422, 68, 186, 633, 42, 68, 587, 633, 42,...   \n1  [710, 229, 175, 561, 516, 68, 393, 175, 14, 42...   \n2  [182, 532, 186, 175, 68, 65, 175, 532, 65, 587...   \n3  [688, 68, 691, 42, 532, 436, 68, 516, 68, 220,...   \n4  [326, 562, 633, 14, 480, 532, 21, 532, 220, 39...   \n\n                                        input_vector  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>enterprise</th>\n      <th>is_irrelevant</th>\n      <th>token_list</th>\n      <th>number_vector</th>\n      <th>input_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20 min line @apple store @short pump.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20 min line @apple store @short pump.</td>\n      <td>[592, 422, 68, 186, 633, 42, 68, 587, 633, 42,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>[710, 229, 175, 561, 516, 68, 393, 175, 14, 42...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Some people should not post replies in #Google...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>Some people should not post replies in #Google...</td>\n      <td>[182, 532, 186, 175, 68, 65, 175, 532, 65, 587...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>[688, 68, 691, 42, 532, 436, 68, 516, 68, 220,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>[326, 562, 633, 14, 480, 532, 21, 532, 220, 39...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = my_lib.Pipeline()\n",
    "raw_df = pipeline.load_data()\n",
    "\n",
    "# DEBUG\n",
    "df = pipeline.encode_to_category(raw_df)\n",
    "df = pipeline.tokenize(df, token_list=[])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline.get_train_test(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model: adaboost\n",
      "train score: 0.90768\n",
      "test score: 0.86445\n",
      "\n",
      "train model: elastic\n",
      "train score: 0.92251\n",
      "test score: 0.88235\n",
      "\n",
      "train model: rf\n",
      "train score: 0.9973\n",
      "test score: 0.85934\n",
      "\n",
      "train model: svm\n",
      "train score: 0.89218\n",
      "test score: 0.86957\n",
      "\n",
      "train model: xgboost\n",
      "[14:34:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.90162\n",
      "test score: 0.84655\n",
      "\n",
      "train model: nn\n",
      "47/47 [==============================] - ETA: 27s - loss: 1.0546 - accuracy: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.6453 - accuracy: 0.8015 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.5552 - accuracy: 0.8218\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.5052 - accuracy: 0.8361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 1s 4ms/step - loss: 0.4892 - accuracy: 0.8406\n",
      "train score: 0.91981\n",
      "test score: 0.88491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_arch = [{\"units\": 256, \"activation\": \"relu\"},\n",
    "           {\"units\": 128, \"activation\": \"relu\"},\n",
    "           {\"units\": 4, \"activation\": \"softmax\"}]\n",
    "\n",
    "model_input_dict = {\"adaboost\": {}, \"elastic\": {}, \"rf\": {}, \"svm\": {}, \"xgboost\": {\"num_class\": 4},\n",
    "                    \"nn\": {\"architecture\": nn_arch, \"num_class\": 4}}\n",
    "\n",
    "\n",
    "model_dict = pipeline.train_model(model_input_dict, X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With special token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               tweet label enterprise  \\\n0              20 min line @apple store @short pump.     1          0   \n1  Nueva tecnología convierte cualquier superfici...     3          1   \n2  Some people should not post replies in #Google...     1          2   \n3  I know a few others having same issue RT @Joel...     2          0   \n4  #Microsoft - We put the \"\"backwards\"\" into bac...     2          1   \n\n   is_irrelevant                                         token_list  \\\n0              0              20 min line @apple store @short pump.   \n1              1  Nueva tecnología convierte cualquier superfici...   \n2              0  Some people should not post replies in #Google...   \n3              0  I know a few others having same issue RT @Joel...   \n4              0  #Microsoft - We put the \"\"backwards\"\" into bac...   \n\n                                       number_vector  \\\n0  [592, 422, 68, 186, 633, 42, 68, 587, 633, 42,...   \n1  [710, 229, 175, 561, 516, 68, 393, 175, 14, 42...   \n2  [182, 532, 186, 175, 68, 65, 175, 532, 65, 587...   \n3  [688, 68, 691, 42, 532, 436, 68, 516, 68, 220,...   \n4  [326, 562, 633, 14, 480, 532, 21, 532, 220, 39...   \n\n                                        input_vector  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>enterprise</th>\n      <th>is_irrelevant</th>\n      <th>token_list</th>\n      <th>number_vector</th>\n      <th>input_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20 min line @apple store @short pump.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20 min line @apple store @short pump.</td>\n      <td>[592, 422, 68, 186, 633, 42, 68, 587, 633, 42,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>[710, 229, 175, 561, 516, 68, 393, 175, 14, 42...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Some people should not post replies in #Google...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>Some people should not post replies in #Google...</td>\n      <td>[182, 532, 186, 175, 68, 65, 175, 532, 65, 587...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>[688, 68, 691, 42, 532, 436, 68, 516, 68, 220,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>[326, 562, 633, 14, 480, 532, 21, 532, 220, 39...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = my_lib.Pipeline()\n",
    "raw_df = pipeline.load_data()\n",
    "\n",
    "# DEBUG\n",
    "df = pipeline.encode_to_category(raw_df)\n",
    "df = pipeline.tokenize(df)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline.get_train_test(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model: adaboost\n",
      "train score: 0.90768\n",
      "test score: 0.86445\n",
      "\n",
      "train model: elastic\n",
      "train score: 0.92251\n",
      "test score: 0.88235\n",
      "\n",
      "train model: rf\n",
      "train score: 0.99596\n",
      "test score: 0.85678\n",
      "\n",
      "train model: svm\n",
      "train score: 0.89218\n",
      "test score: 0.86957\n",
      "\n",
      "train model: xgboost\n",
      "[14:38:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score: 0.90162\n",
      "test score: 0.84655\n",
      "\n",
      "train model: nn\n",
      "47/47 [==============================] - ETA: 23s - loss: 2.1407 - accuracy: 0.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 1.0448 - accuracy: 0.5787 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.8605 - accuracy: 0.6558\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 0.7523 - accuracy: 0.7019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 1s 4ms/step - loss: 0.7257 - accuracy: 0.7133\n",
      "train score: 0.9124\n",
      "test score: 0.86957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_arch = [{\"units\": 256, \"activation\": \"relu\"},\n",
    "           {\"units\": 128, \"activation\": \"relu\"},\n",
    "           {\"units\": 4, \"activation\": \"softmax\"}]\n",
    "\n",
    "model_input_dict = {\"adaboost\": {}, \"elastic\": {}, \"rf\": {}, \"svm\": {}, \"xgboost\": {\"num_class\": 4},\n",
    "                    \"nn\": {\"architecture\": nn_arch, \"num_class\": 4}}\n",
    "\n",
    "\n",
    "model_with_token_dict = pipeline.train_model(model_input_dict, X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}