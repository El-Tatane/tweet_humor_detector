{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import my_lib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               tweet label enterprise  \\\n0              20 min line @apple store @short pump.     1          0   \n1  Nueva tecnología convierte cualquier superfici...     3          1   \n2  Some people should not post replies in #Google...     1          2   \n3  I know a few others having same issue RT @Joel...     2          0   \n4  #Microsoft - We put the \"\"backwards\"\" into bac...     2          1   \n\n   is_irrelevant                                         token_list  \\\n0              0              20 min line @apple store @short pump.   \n1              1  nueva tecnología convierte cualquier superfici...   \n2              0  some people should not post replies in #google...   \n3              0  i know a few others having same issue rt @joel...   \n4              0  #microsoft - we put the \"\"backwards\"\" into bac...   \n\n                                         clean_tweet  \\\n0            20 min line @apple store @short pump .    \n1  nueva tecnología convierte cualquier superfici...   \n2  some people should not post replies in #google...   \n3  i know a few others having same issue rt @joel...   \n4  #microsoft - we put the  \"  \" backwards \"  \"  ...   \n\n                                       number_vector  \\\n0  [414, 669, 408, 115, 544, 52, 408, 202, 544, 5...   \n1  [52, 443, 198, 127, 419, 408, 205, 198, 172, 5...   \n2  [368, 110, 115, 198, 408, 602, 198, 110, 602, ...   \n3  [544, 408, 502, 52, 110, 547, 408, 419, 408, 6...   \n4  [671, 115, 544, 172, 312, 110, 368, 110, 651, ...   \n\n                                        input_vector  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>enterprise</th>\n      <th>is_irrelevant</th>\n      <th>token_list</th>\n      <th>clean_tweet</th>\n      <th>number_vector</th>\n      <th>input_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20 min line @apple store @short pump.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20 min line @apple store @short pump.</td>\n      <td>20 min line @apple store @short pump .</td>\n      <td>[414, 669, 408, 115, 544, 52, 408, 202, 544, 5...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n      <td>[52, 443, 198, 127, 419, 408, 205, 198, 172, 5...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Some people should not post replies in #Google...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>some people should not post replies in #google...</td>\n      <td>some people should not post replies in #google...</td>\n      <td>[368, 110, 115, 198, 408, 602, 198, 110, 602, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>i know a few others having same issue rt @joel...</td>\n      <td>i know a few others having same issue rt @joel...</td>\n      <td>[544, 408, 502, 52, 110, 547, 408, 419, 408, 6...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>#microsoft - we put the \"\"backwards\"\" into bac...</td>\n      <td>#microsoft - we put the  \"  \" backwards \"  \"  ...</td>\n      <td>[671, 115, 544, 172, 312, 110, 368, 110, 651, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = my_lib.Pipeline()\n",
    "raw_df = pipeline.load_data()\n",
    "raw_df = pipeline.encode_to_category(raw_df)\n",
    "raw_df = pipeline.tokenize(raw_df)\n",
    "raw_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE -> train : (3338, 2), test : (835, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  label                                        clean_tweet\n0     1            20 min line @apple store @short pump . \n1     3  nueva tecnología convierte cualquier superfici...\n2     1  some people should not post replies in #google...\n3     2  i know a few others having same issue rt @joel...\n4     2  #microsoft - we put the  \"  \" backwards \"  \"  ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>clean_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20 min line @apple store @short pump .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>some people should not post replies in #google...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>i know a few others having same issue rt @joel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>#microsoft - we put the  \"  \" backwards \"  \"  ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = raw_df.loc[raw_df.label.isin([0,2])]\n",
    "df = raw_df.loc[raw_df.label.isin([0,1,2,3])]\n",
    "df = my_lib.processing.remove_useless_col(df, keep_col_list=[\"label\", \"clean_tweet\"])\n",
    "df_train_data, df_test_data = my_lib.processing.split_data(df)\n",
    "print(f\"SHAPE -> train : {df_train_data.shape}, test : {df_test_data.shape}\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "for label_id, label_name in enumerate([\"pos\", \"neu\", \"neg\", \"irr\"]):\n",
    "    tmp_df = df.loc[df[\"label\"]==label_id, [\"clean_tweet\"]]\n",
    "    for idx, row in tmp_df.iterrows():\n",
    "        row.to_csv(f\"/data/tensorflow_bert_data/{label_name}/text_{idx}.txt\", sep=\" \", index=None,\n",
    "                quotechar=\" \", header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_265', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", num_labels=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = tf.keras.preprocessing.text_dataset_from_directory('/data/tensorflow_bert_data/', seed=123, batch_size=30000)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in data.take(1):\n",
    "  train_feat = i[0].numpy()\n",
    "  train_lab = i[1].numpy()\n",
    "\n",
    "df_data = pd.DataFrame([train_feat, train_lab]).T\n",
    "df_data.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "df_data['DATA_COLUMN'] = df_data['DATA_COLUMN'].str.decode(\"utf-8\")\n",
    "print(df_data.shape)\n",
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "row_number = len(df_data)\n",
    "print(row_number)\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    tmp_df = df_data.loc[df_data[\"LABEL_COLUMN\"]==i]\n",
    "\n",
    "    msk = np.random.rand(len(tmp_df)) < 0.8\n",
    "    df_train = pd.concat([df_train, tmp_df[msk]])\n",
    "    df_test = pd.concat([df_test, tmp_df[~msk]])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[[\"DATA_COLUMN\", \"LABEL_COLUMN\"]].groupby(\"LABEL_COLUMN\").count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test[[\"DATA_COLUMN\", \"LABEL_COLUMN\"]].groupby(\"LABEL_COLUMN\").count()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN):\n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  return train_InputExamples, validation_InputExamples\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(df_train,\n",
    "                                                                           df_test,\n",
    "                                                                           'DATA_COLUMN',\n",
    "                                                                           'LABEL_COLUMN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(df_train, df_test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)\n",
    "\n",
    "pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\n",
    "                  'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}