{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.49 seconds)\n",
      "Writing emoji data to /root/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import my_lib\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               tweet label enterprise  \\\n0              20 min line @apple store @short pump.     1          0   \n1  Nueva tecnología convierte cualquier superfici...     3          1   \n2  Some people should not post replies in #Google...     1          2   \n3  I know a few others having same issue RT @Joel...     2          0   \n4  #Microsoft - We put the \"\"backwards\"\" into bac...     2          1   \n\n   is_irrelevant                                         token_list  \\\n0              0              20 min line @apple store @short pump.   \n1              1  nueva tecnología convierte cualquier superfici...   \n2              0  some people should not post replies in #google...   \n3              0  i know a few others having same issue rt @joel...   \n4              0  #microsoft - we put the \"\"backwards\"\" into bac...   \n\n                                         clean_tweet  \\\n0            20 min line @apple store @short pump .    \n1  nueva tecnología convierte cualquier superfici...   \n2  some people should not post replies in #google...   \n3  i know a few others having same issue rt @joel...   \n4  #microsoft - we put the  \"  \" backwards \"  \"  ...   \n\n                                       number_vector  \\\n0  [68, 185, 431, 268, 128, 606, 431, 329, 128, 6...   \n1  [606, 194, 638, 661, 415, 431, 652, 638, 472, ...   \n2  [15, 302, 268, 638, 431, 57, 638, 302, 57, 329...   \n3  [128, 431, 317, 606, 302, 650, 431, 415, 431, ...   \n4  [220, 268, 128, 472, 86, 302, 15, 302, 331, 65...   \n\n                                        input_vector  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>enterprise</th>\n      <th>is_irrelevant</th>\n      <th>token_list</th>\n      <th>clean_tweet</th>\n      <th>number_vector</th>\n      <th>input_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20 min line @apple store @short pump.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20 min line @apple store @short pump.</td>\n      <td>20 min line @apple store @short pump .</td>\n      <td>[68, 185, 431, 268, 128, 606, 431, 329, 128, 6...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n      <td>[606, 194, 638, 661, 415, 431, 652, 638, 472, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Some people should not post replies in #Google...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>some people should not post replies in #google...</td>\n      <td>some people should not post replies in #google...</td>\n      <td>[15, 302, 268, 638, 431, 57, 638, 302, 57, 329...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I know a few others having same issue RT @Joel...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>i know a few others having same issue rt @joel...</td>\n      <td>i know a few others having same issue rt @joel...</td>\n      <td>[128, 431, 317, 606, 302, 650, 431, 415, 431, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>#microsoft - we put the \"\"backwards\"\" into bac...</td>\n      <td>#microsoft - we put the  \"  \" backwards \"  \"  ...</td>\n      <td>[220, 268, 128, 472, 86, 302, 15, 302, 331, 65...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = my_lib.Pipeline()\n",
    "raw_df = pipeline.load_data()\n",
    "raw_df = pipeline.encode_to_category(raw_df)\n",
    "raw_df = pipeline.tokenize(raw_df)\n",
    "raw_df.head()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE -> train : (3338, 2), test : (835, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  label                                        clean_tweet\n0     1            20 min line @apple store @short pump . \n1     3  nueva tecnología convierte cualquier superfici...\n2     1  some people should not post replies in #google...\n3     2  i know a few others having same issue rt @joel...\n4     2  #microsoft - we put the  \"  \" backwards \"  \"  ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>clean_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20 min line @apple store @short pump .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>nueva tecnología convierte cualquier superfici...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>some people should not post replies in #google...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>i know a few others having same issue rt @joel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>#microsoft - we put the  \"  \" backwards \"  \"  ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = raw_df.loc[raw_df.label.isin([0,2])]\n",
    "df = raw_df.loc[raw_df.label.isin([0,1,2,3])]\n",
    "df = my_lib.processing.remove_useless_col(df, keep_col_list=[\"label\", \"clean_tweet\"])\n",
    "df_train_data, df_test_data = my_lib.processing.split_data(df)\n",
    "print(f\"SHAPE -> train : {df_train_data.shape}, test : {df_test_data.shape}\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for label_id, label_name in enumerate([\"pos\", \"neu\", \"neg\", \"irr\"]):\n",
    "    tmp_df = df.loc[df[\"label\"]==label_id, [\"clean_tweet\"]]\n",
    "    for idx, row in tmp_df.iterrows():\n",
    "        row.to_csv(f\"/data/tensorflow_bert_data/{label_name}/text_{idx}.txt\", sep=\" \", index=None,\n",
    "                quotechar=\" \", header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_37', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", num_labels=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 files belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.keras.preprocessing.text_dataset_from_directory('/data/tensorflow_bert_data/', seed=123, batch_size=30000)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         DATA_COLUMN LABEL_COLUMN\n0   rt  @remcovandenhout  :    meest  comfortabel...            0\n1   omg  @apple  why  the  fuck  did  you  delete...            1\n2   rt  @lcmediahouse  :    4chan  '  s  chris  p...            1\n3   #twitter  keeps  me  from  sleeping  !    #so...            2\n4   would  it  kill  @apple  to  put  a  braille ...            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATA_COLUMN</th>\n      <th>LABEL_COLUMN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt  @remcovandenhout  :    meest  comfortabel...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>omg  @apple  why  the  fuck  did  you  delete...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rt  @lcmediahouse  :    4chan  '  s  chris  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#twitter  keeps  me  from  sleeping  !    #so...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>would  it  kill  @apple  to  put  a  braille ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data.take(1):\n",
    "  train_feat = i[0].numpy()\n",
    "  train_lab = i[1].numpy()\n",
    "\n",
    "df_data = pd.DataFrame([train_feat, train_lab]).T\n",
    "df_data.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "df_data['DATA_COLUMN'] = df_data['DATA_COLUMN'].str.decode(\"utf-8\")\n",
    "print(df_data.shape)\n",
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173\n"
     ]
    },
    {
     "data": {
      "text/plain": "((2970, 2), (776, 2))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_number = len(df_data)\n",
    "print(row_number)\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    tmp_df = df_data.loc[df_data[\"LABEL_COLUMN\"]==i]\n",
    "\n",
    "    msk = np.random.rand(len(tmp_df)) < 0.8\n",
    "    df_train = pd.concat([df_train, tmp_df[msk]])\n",
    "    df_test = pd.concat([df_test, tmp_df[~msk]])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "              DATA_COLUMN\nLABEL_COLUMN             \n0                    1099\n1                     391\n2                    1480",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATA_COLUMN</th>\n    </tr>\n    <tr>\n      <th>LABEL_COLUMN</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1099</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1480</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"DATA_COLUMN\", \"LABEL_COLUMN\"]].groupby(\"LABEL_COLUMN\").count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "              DATA_COLUMN\nLABEL_COLUMN             \n0                     290\n1                      95\n2                     391",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATA_COLUMN</th>\n    </tr>\n    <tr>\n      <th>LABEL_COLUMN</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>391</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[[\"DATA_COLUMN\", \"LABEL_COLUMN\"]].groupby(\"LABEL_COLUMN\").count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_train = shuffle(df_train)\n",
    "df_test = shuffle(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN):\n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  return train_InputExamples, validation_InputExamples\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(df_train,\n",
    "                                                                           df_test,\n",
    "                                                                           'DATA_COLUMN',\n",
    "                                                                           'LABEL_COLUMN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(df_train, df_test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  3076      \n",
      "=================================================================\n",
      "Total params: 109,485,316\n",
      "Trainable params: 109,485,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "      7/Unknown - 76s 76s/step - loss: 1.4721 - accuracy: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 93s 17s/step - loss: 1.4610 - accuracy: 0.1484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 110s 17s/step - loss: 1.4297 - accuracy: 0.1997\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 124s 16s/step - loss: 1.4081 - accuracy: 0.2240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 139s 16s/step - loss: 1.3911 - accuracy: 0.2429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 155s 16s/step - loss: 1.3733 - accuracy: 0.2641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 170s 16s/step - loss: 1.3557 - accuracy: 0.2850"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\n",
    "#                   'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']\n",
    "#\n",
    "# tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "# tf_outputs = model(tf_batch)\n",
    "# tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "# labels = ['Negative','Positive']\n",
    "# label = tf.argmax(tf_predictions, axis=1)\n",
    "# label = label.numpy()\n",
    "# for i in range(len(pred_sentences)):\n",
    "#   print(pred_sentences[i], \": \\n\", labels[label[i]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('/app/models/multi_class_bert_2')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"a\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = ['irr','neg', 'neu', 'pos']\n",
    "\n",
    "def predict(sentence_list):\n",
    "\n",
    "    tf_batch = tokenizer(sentence_list, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "    tf_outputs = model(tf_batch)\n",
    "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "    label = tf.argmax(tf_predictions, axis=1)\n",
    "    label = label.numpy()\n",
    "    return label\n",
    "    # for i in range(len(sentence_list)):\n",
    "    #   print(sentence_list[i], \": \\n\", labels[label[i]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "sen_list = list(df_test[\"DATA_COLUMN\"].values)\n",
    "res_pred = predict(sen_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_re = df_test.copy()\n",
    "df_re[\"predict\"] = res_pred\n",
    "df_re.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_re.loc[df_re[\"LABEL_COLUMN\"] != df_re[\"predict\"]].head(60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "m = my_lib.model.BERT().load(\"/app/models/multi_class_bert\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m.predict([\"Hi how are you my friend\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "tf_batch = m.tokenizer([\"Hi how are you my friend.\"], max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = m.model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}